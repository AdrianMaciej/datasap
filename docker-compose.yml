version: '2'

services:
  spark:
    build: 
      dockerfile: submit_aws.dockerfile
      context: dockers
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - AWS_ACCESS_KEY_ID=FAKE
      - AWS_SECRET_ACCESS_KEY=FAKE
    ports:
      - '8080:8080'
    volumes:
      - "${PWD}/:/work:rw"
      - ./spark/_jars_dir:/opt/bitnami/spark/jars/ivy:rw
      - ./spark/_cache_dir:/opt/bitnami/spark/.ivy2:rw
  spark-worker:
    build: 
      dockerfile: submit_aws.dockerfile
      context: dockers
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - AWS_ACCESS_KEY_ID=FAKE
      - AWS_SECRET_ACCESS_KEY=FAKE
    volumes:
      - "${PWD}/:/work:rw"
      - ./spark/_jars_dir:/opt/bitnami/spark/jars/ivy:rw
      - ./spark/_cache_dir:/opt/bitnami/spark/.ivy2:rw
  localstack:
    image: localstack/localstack:latest
    environment:
      - AWS_DEFAULT_REGION=us-east-1
      - EDGE_PORT=4572
      - SERVICES=s3
      - DATA_DIR=/tmp/localstack/data
    ports:
      - '4566-4583:4566-4583'
    volumes:
      - "/tmp/localstack:/tmp/localstack"
      - "/var/run/docker.sock:/var/run/docker.sock"
